# HDF5 1.10.5+ Support Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Lower minimum HDF5 requirement from 1.12.0 to 1.10.5 for compatibility with Ubuntu packages and other ecosystems (HDF5.jl, h5py).

**Architecture:** Runtime version detection at library init, with version-dependent API branching through wrapper functions. LocationToken becomes an enum supporting both `haddr_t` (pre-1.12) and `H5O_token_t` (1.12+).

**Tech Stack:** Rust, HDF5 C API, libloading for runtime symbol loading

---

## Summary of Changes

1. **Version Detection**: Add global static to store detected HDF5 version at init
2. **Type Additions**: Add `H5O_info1_t` type for pre-1.12 API
3. **Function Loading**: Add optional loading of pre-1.12 functions (`H5Oget_info1`, `H5Oopen_by_addr`)
4. **LocationToken**: Change from newtype wrapper to enum with Address/Token variants
5. **Wrapper Functions**: Create `h5o_get_info`, `h5o_open_by_token` that branch by version
6. **CI Updates**: Test both HDF5 1.10.x (apt) and 1.12.x+ (conda-forge)

---

### Task 1: Add Version Storage and Detection in runtime.rs

**Files:**
- Modify: `hdf5/src/sys/runtime.rs:770-841` (version checking area)

**Step 1: Write the failing test**

Create a test that checks version is stored and retrievable.

```rust
// In hdf5/src/sys/runtime.rs, add to the end of the file
#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_hdf5_version_stored() {
        // Initialize if not already
        if !is_initialized() {
            init(None).expect("Failed to initialize HDF5");
        }
        let version = hdf5_version();
        assert!(version.major >= 1);
        assert!(version.minor >= 10);
    }
}
```

**Step 2: Run test to verify it fails**

Run: `cargo test --package hdf5 test_hdf5_version_stored -- --nocapture`
Expected: FAIL with "cannot find function `hdf5_version`"

**Step 3: Add version storage and accessor**

Add after line 773 (after `LIBRARY_PATH` definition):

```rust
static HDF5_VERSION: OnceLock<Version> = OnceLock::new();

/// Get the detected HDF5 library version.
/// Returns None if the library is not initialized.
pub fn hdf5_version() -> Version {
    *HDF5_VERSION.get().expect("HDF5 library not initialized")
}

/// Check if HDF5 version is at least the specified version.
pub fn hdf5_version_at_least(major: u8, minor: u8, micro: u8) -> bool {
    let v = hdf5_version();
    (v.major, v.minor, v.micro) >= (major, minor, micro)
}
```

**Step 4: Modify check_hdf5_version to store version**

Replace the `check_hdf5_version` function:

```rust
/// Check that the HDF5 library version is at least 1.10.5.
/// Stores the version for later queries.
fn check_hdf5_version() -> Result<(), String> {
    let mut major: c_uint = 0;
    let mut minor: c_uint = 0;
    let mut release: c_uint = 0;
    unsafe {
        H5get_libversion(&mut major, &mut minor, &mut release);
    }

    let version = Version {
        major: major as u8,
        minor: minor as u8,
        micro: release as u8,
    };

    HDF5_VERSION.set(version).map_err(|_| "Version already set".to_string())?;

    if major < 1 || (major == 1 && minor < 10) || (major == 1 && minor == 10 && release < 5) {
        return Err(format!(
            "HDF5 {}.{}.{} is not supported. Minimum required version is 1.10.5",
            major, minor, release
        ));
    }
    Ok(())
}
```

**Step 5: Run test to verify it passes**

Run: `cargo test --package hdf5 test_hdf5_version_stored -- --nocapture`
Expected: PASS

**Step 6: Commit**

```bash
git add hdf5/src/sys/runtime.rs
git commit -m "feat: add HDF5 version storage and detection

- Add HDF5_VERSION global static to store detected version
- Add hdf5_version() and hdf5_version_at_least() accessors
- Change minimum version from 1.12.0 to 1.10.5

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>"
```

---

### Task 2: Add H5O_info1_t Type for Pre-1.12 API

**Files:**
- Modify: `hdf5/src/sys/runtime.rs:556-568` (near H5O_info2_t definition)

**Step 1: Write the failing test**

```rust
#[test]
fn test_h5o_info1_t_exists() {
    // This test just verifies the type exists and has expected size
    let info: H5O_info1_t = unsafe { std::mem::zeroed() };
    // H5O_info1_t has different size than H5O_info2_t
    // info1 uses haddr_t (8 bytes), info2 uses H5O_token_t (16 bytes)
    assert!(std::mem::size_of::<H5O_info1_t>() > 0);
}
```

**Step 2: Run test to verify it fails**

Run: `cargo test --package hdf5 test_h5o_info1_t_exists -- --nocapture`
Expected: FAIL with "cannot find type `H5O_info1_t`"

**Step 3: Add H5O_info1_t type definition**

Add after H5O_info2_t definition (around line 568):

```rust
/// Object info structure for HDF5 < 1.12 (uses haddr_t instead of token)
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct H5O_info1_t {
    pub fileno: c_ulong,
    pub addr: haddr_t,
    pub type_: H5O_type_t,
    pub rc: c_uint,
    pub atime: i64,
    pub mtime: i64,
    pub ctime: i64,
    pub btime: i64,
    pub num_attrs: hsize_t,
    // Note: The full H5O_info1_t has more fields (hdr, meta_size),
    // but we only need the basic fields for our use case.
    // We'll use H5O_INFO_BASIC flag which only fills these fields.
}
```

**Step 4: Run test to verify it passes**

Run: `cargo test --package hdf5 test_h5o_info1_t_exists -- --nocapture`
Expected: PASS

**Step 5: Commit**

```bash
git add hdf5/src/sys/runtime.rs
git commit -m "feat: add H5O_info1_t type for HDF5 < 1.12

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>"
```

---

### Task 3: Add Pre-1.12 Function Loading (H5Oget_info1, H5Oopen_by_addr)

**Files:**
- Modify: `hdf5/src/sys/runtime.rs:1260-1285` (H5O functions area)

**Step 1: Add conditional function loading**

Since these functions only exist in HDF5 < 1.12, we need a different approach than `hdf5_function!` macro. We'll use optional function loading.

Add after existing H5O functions (around line 1285):

```rust
// Pre-1.12 functions (loaded conditionally)
// These are loaded using try_get instead of get to avoid panic on 1.12+

/// H5Oget_info1 - Available in HDF5 < 1.12
/// Returns None if the function is not available (HDF5 >= 1.12)
pub unsafe fn H5Oget_info1(loc_id: hid_t, oinfo: *mut H5O_info1_t, fields: c_uint) -> Option<herr_t> {
    let lib = get_library();
    let func: Option<Symbol<unsafe extern "C" fn(hid_t, *mut H5O_info1_t, c_uint) -> herr_t>> =
        lib.get(b"H5Oget_info1").ok();
    func.map(|f| f(loc_id, oinfo, fields))
}

/// H5Oget_info_by_name1 - Available in HDF5 < 1.12
pub unsafe fn H5Oget_info_by_name1(
    loc_id: hid_t,
    name: *const c_char,
    oinfo: *mut H5O_info1_t,
    fields: c_uint,
    lapl_id: hid_t,
) -> Option<herr_t> {
    let lib = get_library();
    let func: Option<Symbol<unsafe extern "C" fn(hid_t, *const c_char, *mut H5O_info1_t, c_uint, hid_t) -> herr_t>> =
        lib.get(b"H5Oget_info_by_name1").ok();
    func.map(|f| f(loc_id, name, oinfo, fields, lapl_id))
}

/// H5Oopen_by_addr - Available in all HDF5 versions
pub unsafe fn H5Oopen_by_addr(loc_id: hid_t, addr: haddr_t) -> hid_t {
    let lib = get_library();
    let func: Symbol<unsafe extern "C" fn(hid_t, haddr_t) -> hid_t> = lib
        .get(b"H5Oopen_by_addr")
        .expect("Failed to load H5Oopen_by_addr");
    func(loc_id, addr)
}
```

**Step 2: Export in h5o module**

Update `hdf5/src/sys/mod.rs` h5o module (around line 267-278):

```rust
pub mod h5o {
    pub use super::runtime::{
        H5O_info1_t, H5O_info2_t, H5O_token_t, H5O_type_t, H5Oclose, H5Ocopy, H5Oget_comment,
        H5Oget_info1, H5Oget_info3, H5Oget_info_by_name1, H5Oget_info_by_name3, H5Oopen,
        H5Oopen_by_addr, H5Oopen_by_token, H5Oset_comment, H5O_COPY_ALL,
        H5O_COPY_EXPAND_EXT_LINK_FLAG, H5O_COPY_EXPAND_REFERENCE_FLAG,
        H5O_COPY_EXPAND_SOFT_LINK_FLAG, H5O_COPY_MERGE_COMMITTED_DTYPE_FLAG,
        H5O_COPY_PRESERVE_NULL_FLAG, H5O_COPY_SHALLOW_HIERARCHY_FLAG, H5O_COPY_WITHOUT_ATTR_FLAG,
        H5O_INFO_ALL, H5O_INFO_BASIC, H5O_INFO_NUM_ATTRS, H5O_INFO_TIME, H5O_SHMESG_ALL_FLAG,
        H5O_SHMESG_ATTR_FLAG, H5O_SHMESG_DTYPE_FLAG, H5O_SHMESG_FILL_FLAG, H5O_SHMESG_NONE_FLAG,
        H5O_SHMESG_PLINE_FLAG, H5O_SHMESG_SDSPACE_FLAG,
    };
}
```

**Step 3: Run cargo check**

Run: `cargo check --package hdf5`
Expected: PASS (no compilation errors)

**Step 4: Commit**

```bash
git add hdf5/src/sys/runtime.rs hdf5/src/sys/mod.rs
git commit -m "feat: add pre-1.12 H5O functions (H5Oget_info1, H5Oopen_by_addr)

- H5Oget_info1 and H5Oget_info_by_name1 loaded conditionally
- H5Oopen_by_addr available in all versions

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>"
```

---

### Task 4: Change LocationToken to Enum with Address/Token Variants

**Files:**
- Modify: `hdf5/src/hl/location.rs:231-243` (LocationToken definition)

**Step 1: Change LocationToken from newtype to enum**

Replace the LocationToken definition:

```rust
/// A token containing the identifier of a [`Location`].
///
/// In HDF5 < 1.12, this is an address (`haddr_t`).
/// In HDF5 >= 1.12, this is a token (`H5O_token_t`).
#[derive(Clone, Copy, Debug, PartialEq, Eq)]
pub enum LocationToken {
    /// Address-based identifier (HDF5 < 1.12)
    Address(haddr_t),
    /// Token-based identifier (HDF5 >= 1.12)
    Token(H5O_token_t),
}
```

**Step 2: Update LocationInfo::from implementation**

The From impl needs to handle both info types. Update the implementation:

```rust
impl LocationInfo {
    /// Create LocationInfo from H5O_info2_t (HDF5 >= 1.12)
    pub(crate) fn from_info2(info: H5O_info2_t) -> Self {
        Self {
            fileno: info.fileno as _,
            token: LocationToken::Token(info.token),
            loc_type: info.type_.into(),
            num_links: info.rc as _,
            atime: info.atime as _,
            mtime: info.mtime as _,
            ctime: info.ctime as _,
            btime: info.btime as _,
            num_attrs: info.num_attrs as _,
        }
    }

    /// Create LocationInfo from H5O_info1_t (HDF5 < 1.12)
    pub(crate) fn from_info1(info: H5O_info1_t) -> Self {
        Self {
            fileno: info.fileno as _,
            token: LocationToken::Address(info.addr),
            loc_type: info.type_.into(),
            num_links: info.rc as _,
            atime: info.atime as _,
            mtime: info.mtime as _,
            ctime: info.ctime as _,
            btime: info.btime as _,
            num_attrs: info.num_attrs as _,
        }
    }
}
```

Remove the old `From<H5O_info2_t>` impl.

**Step 3: Update H5O_get_info and H5O_open_by_token functions**

Replace the wrapper functions with version-branching implementations:

```rust
use crate::sys::{hdf5_version_at_least, H5O_info1_t};

#[allow(non_snake_case)]
fn H5O_get_info(loc_id: hid_t, full: bool) -> Result<LocationInfo> {
    if hdf5_version_at_least(1, 12, 0) {
        // HDF5 >= 1.12: Use H5Oget_info3 with H5O_info2_t
        let mut info_buf = MaybeUninit::uninit();
        let info_ptr = info_buf.as_mut_ptr();
        h5call!(H5Oget_info3(loc_id, info_ptr, info_fields(full)))?;
        let info = unsafe { info_buf.assume_init() };
        Ok(LocationInfo::from_info2(info))
    } else {
        // HDF5 < 1.12: Use H5Oget_info1 with H5O_info1_t
        let mut info_buf: MaybeUninit<H5O_info1_t> = MaybeUninit::uninit();
        let info_ptr = info_buf.as_mut_ptr();
        let result = unsafe { H5Oget_info1(loc_id, info_ptr, info_fields(full)) };
        match result {
            Some(ret) if ret >= 0 => {
                let info = unsafe { info_buf.assume_init() };
                Ok(LocationInfo::from_info1(info))
            }
            Some(_) => Err(Error::query()),
            None => fail!("H5Oget_info1 not available"),
        }
    }
}

#[allow(non_snake_case)]
fn H5O_get_info_by_name(loc_id: hid_t, name: *const c_char, full: bool) -> Result<LocationInfo> {
    if hdf5_version_at_least(1, 12, 0) {
        let mut info_buf = MaybeUninit::uninit();
        let info_ptr = info_buf.as_mut_ptr();
        h5call!(H5Oget_info_by_name3(loc_id, name, info_ptr, info_fields(full), H5P_DEFAULT))?;
        let info = unsafe { info_buf.assume_init() };
        Ok(LocationInfo::from_info2(info))
    } else {
        let mut info_buf: MaybeUninit<H5O_info1_t> = MaybeUninit::uninit();
        let info_ptr = info_buf.as_mut_ptr();
        let result = unsafe { H5Oget_info_by_name1(loc_id, name, info_ptr, info_fields(full), H5P_DEFAULT) };
        match result {
            Some(ret) if ret >= 0 => {
                let info = unsafe { info_buf.assume_init() };
                Ok(LocationInfo::from_info1(info))
            }
            Some(_) => Err(Error::query()),
            None => fail!("H5Oget_info_by_name1 not available"),
        }
    }
}

#[allow(non_snake_case)]
fn H5O_open_by_token(loc_id: hid_t, token: LocationToken) -> Result<Location> {
    match token {
        LocationToken::Token(t) => {
            Location::from_id(h5call!(H5Oopen_by_token(loc_id, t))?)
        }
        LocationToken::Address(addr) => {
            let id = unsafe { H5Oopen_by_addr(loc_id, addr) };
            if id < 0 {
                Err(Error::query())
            } else {
                Location::from_id(id)
            }
        }
    }
}
```

**Step 4: Update imports**

Update the imports at the top of location.rs:

```rust
use crate::sys::h5o::{
    H5O_info1_t, H5O_info2_t, H5O_token_t, H5Oget_info1, H5Oget_info3,
    H5Oget_info_by_name1, H5Oget_info_by_name3, H5Oopen_by_addr, H5Oopen_by_token,
    H5O_INFO_BASIC, H5O_INFO_NUM_ATTRS, H5O_INFO_TIME,
};
use crate::sys::{haddr_t, hdf5_version_at_least};
```

**Step 5: Run tests**

Run: `cargo test --package hdf5 test_location_info -- --nocapture`
Expected: PASS

**Step 6: Commit**

```bash
git add hdf5/src/hl/location.rs
git commit -m "feat: change LocationToken to enum for pre-1.12 support

- LocationToken now has Address and Token variants
- H5O_get_info branches by HDF5 version
- H5O_open_by_token uses appropriate API based on token type

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>"
```

---

### Task 5: Export Version Functions from sys module

**Files:**
- Modify: `hdf5/src/sys/mod.rs:614-630` (bottom of file)

**Step 1: Export version functions**

Add to the public API at the end of mod.rs:

```rust
/// Get the detected HDF5 library version.
pub fn hdf5_version() -> runtime::Version {
    runtime::hdf5_version()
}

/// Check if HDF5 version is at least the specified version.
pub fn hdf5_version_at_least(major: u8, minor: u8, micro: u8) -> bool {
    runtime::hdf5_version_at_least(major, minor, micro)
}
```

Also export `haddr_t` from h5 module if not already:

```rust
pub mod h5 {
    pub use super::runtime::{
        c_char, c_double, c_float, c_int, c_long, c_uint, c_ulong, c_void, haddr_t, hbool_t,
        herr_t, hid_t, hsize_t, hssize_t, htri_t, size_t, ssize_t, H5_index_t, H5_iter_order_t,
        // ... rest of exports
    };
}
```

**Step 2: Run cargo check**

Run: `cargo check --package hdf5`
Expected: PASS

**Step 3: Commit**

```bash
git add hdf5/src/sys/mod.rs
git commit -m "feat: export version functions from sys module

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>"
```

---

### Task 6: Update CI to Test Multiple HDF5 Versions

**Files:**
- Modify: `.github/workflows/ci.yml`

**Step 1: Update test matrix to include HDF5 version testing**

Replace the test job to test both 1.10.x and 1.12+:

```yaml
  test:
    name: test (${{ matrix.os }}, HDF5 ${{ matrix.hdf5 }})
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        include:
          # Ubuntu with system HDF5 (1.10.x)
          - os: ubuntu-22.04
            hdf5: "system"
          # Ubuntu with conda HDF5 1.12
          - os: ubuntu-22.04
            hdf5: "1.12"
          # Ubuntu with conda HDF5 1.14
          - os: ubuntu-24.04
            hdf5: "1.14"
    steps:
      - name: Checkout repository
        uses: actions/checkout@v6
      - name: Install Rust
        uses: dtolnay/rust-toolchain@stable
      - name: Install system HDF5 (1.10.x)
        if: matrix.hdf5 == 'system'
        run: sudo apt-get update && sudo apt-get install -y libhdf5-dev
      - name: Setup Conda
        if: matrix.hdf5 != 'system'
        uses: conda-incubator/setup-miniconda@v3
        with:
          auto-update-conda: true
          python-version: "3.11"
      - name: Install HDF5 from conda-forge
        if: matrix.hdf5 != 'system'
        shell: bash -el {0}
        run: conda install -c conda-forge "hdf5>=${{ matrix.hdf5 }},<${{ matrix.hdf5 == '1.12' && '1.13' || '1.15' }}"
      - name: Build
        shell: bash -el {0}
        run: cargo build --workspace --verbose
      - name: Run tests
        shell: bash -el {0}
        run: cargo test --workspace --verbose
```

**Step 2: Update interop tests to use conda HDF5**

The Julia and Python interop tests should continue using conda-forge HDF5 1.12+.

**Step 3: Run CI locally (optional)**

Run: `cargo test --workspace`
Expected: PASS on local machine

**Step 4: Commit**

```bash
git add .github/workflows/ci.yml
git commit -m "ci: test multiple HDF5 versions (1.10.x, 1.12, 1.14)

- Add matrix for HDF5 version testing
- Ubuntu system HDF5 (1.10.x) tests compatibility
- Conda HDF5 1.12 and 1.14 test newer features

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>"
```

---

### Task 7: Run Full Test Suite and Fix Any Issues

**Files:**
- Potentially various files depending on test failures

**Step 1: Run full test suite**

Run: `cargo test --workspace`

**Step 2: Run clippy**

Run: `cargo clippy --workspace -- -D warnings`

**Step 3: Run fmt**

Run: `cargo fmt --all`

**Step 4: Fix any issues found**

Address compilation errors, warnings, or test failures.

**Step 5: Commit fixes**

```bash
git add -A
git commit -m "fix: address test and lint issues

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>"
```

---

### Task 8: Create Pull Request

**Step 1: Push branch**

```bash
git push -u origin feat/hdf5-1.10.5-support
```

**Step 2: Create PR**

```bash
gh pr create --title "feat: support HDF5 1.10.5+" --body "$(cat <<'EOF'
## Summary
- Lower minimum HDF5 requirement from 1.12.0 to 1.10.5
- Add runtime version detection and branching
- LocationToken now supports both address (pre-1.12) and token (1.12+) modes
- CI tests multiple HDF5 versions

## Changes
- Add version storage and `hdf5_version()`, `hdf5_version_at_least()` accessors
- Add `H5O_info1_t` type for pre-1.12 API
- Add optional loading of `H5Oget_info1`, `H5Oopen_by_addr`
- Change `LocationToken` to enum with `Address`/`Token` variants
- Update CI matrix to test 1.10.x, 1.12, and 1.14

## Test plan
- [ ] Tests pass with HDF5 1.10.x (Ubuntu system packages)
- [ ] Tests pass with HDF5 1.12+ (conda-forge)
- [ ] Tests pass with HDF5 1.14 (conda-forge)
- [ ] Julia interop tests pass
- [ ] Python interop tests pass

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)
EOF
)"
```

**Step 3: Enable auto-merge**

```bash
gh pr merge --auto --squash --delete-branch
```

---

## Execution Options

**Plan complete and saved to `docs/plans/2026-02-05-hdf5-1.10.5-support-plan.md`.**

Two execution options:

**1. Subagent-Driven (this session)** - I dispatch fresh subagent per task, review between tasks, fast iteration

**2. Parallel Session (separate)** - Open new session with executing-plans, batch execution with checkpoints

Which approach?
